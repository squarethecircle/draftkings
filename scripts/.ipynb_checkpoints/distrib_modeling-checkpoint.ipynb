{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up imports and load data\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from constants import *\n",
    "\n",
    "CUR_YEAR = 2015\n",
    "CUR_WEEK = 9\n",
    "\n",
    "quants={'STD', 'SKEW', 'PZ'}\n",
    "hf = pd.concat([pd.read_pickle('../data/histdata').dropna(), pd.read_pickle('../data/curprojs')])\n",
    "hf['Opp']=hf.apply(lambda r: r['Matchup'].split(' ')[2] if isinstance(r['Matchup'],str) else 'NA',axis=1)\n",
    "sals = pd.read_csv('../data/DKSalariesCurrent.csv')\n",
    "sals['PID'] = sals.apply(lambda r: generate_pid(r['Name'], r['Position']),axis=1)\n",
    "sals['Week'] = CUR_WEEK\n",
    "sals['Year'] = CUR_YEAR\n",
    "hf = hf.merge(sals[['PID', 'Week', 'Year', 'Salary']], on=['PID', 'Week', 'Year'], how='left')\n",
    "hf['Salary_x'] = hf.apply(lambda r: r['Salary_x'] if not np.isnan(r['Salary_x']) else r['Salary_y'], axis=1)\n",
    "hf.drop('Salary_y', axis=1)\n",
    "hf.rename(columns={'Salary_x':'Salary'}, inplace=True)\n",
    "pids = hf['PID'].unique()\n",
    "pos = hf['Pos'].unique()\n",
    "nums = dict([(pid, hf[hf['PID']==pid].shape[0]) for pid in pids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc sample mean, skew and std for every player with 10+ games in our dataset\n",
    "pf = pd.DataFrame(pids, columns=['PID'])\n",
    "pf['N'] = pf.PID.apply(lambda r: sum(hf.PID==r))\n",
    "pf['Pos'] = pf.PID.apply(lambda r: r.split('_')[-1])\n",
    "pf=pf[pf.N >= 10]\n",
    "for i,r in pf.iterrows():\n",
    "    dat=hf[hf.PID==r.PID]['Points'].dropna().values\n",
    "    pf.set_value(i, 'PZ', 1-np.count_nonzero(dat)*1./dat.size)\n",
    "    dat = dat[dat != 0]\n",
    "    pf.set_value(i, 'MEAN', dat.mean())\n",
    "    pf.set_value(i, 'SKEW', stats.skew(dat))\n",
    "    pf.set_value(i, 'STD', dat.std()*np.sqrt(dat.size*1./(dat.size-1))) #unbiased estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit and output functions that model skew, stdev, and pctzero dependent on ppg\n",
    "outp=['Pos,Quantity,2,1,0\\n']\n",
    "for p in pos:\n",
    "    thispos = pf[pf['Pos']==p]\n",
    "    std_func=np.poly1d(np.polyfit(thispos['MEAN'], thispos['STD'],2))\n",
    "    skew_func=np.poly1d(np.polyfit(thispos['MEAN'], thispos['SKEW'],2))\n",
    "    pz_func=np.poly1d(np.polyfit(thispos['MEAN'], thispos['PZ'],2))\n",
    "    outp.append('{},STD,{},{},{}\\n'.format(p, *std_func.c))\n",
    "    outp.append('{},SKEW,{},{},{}\\n'.format(p, *skew_func.c))\n",
    "    outp.append('{},PZ,{},{},{}\\n'.format(p, *pz_func.c if len(pz_func.c)==3 else [0,0,0]))\n",
    "with open('params.csv', 'w') as wr:\n",
    "    wr.writelines(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/pandas/core/frame.py:1942: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# read params from file (to allow for manual adjustments which are necessary as some of the fits)\n",
    "# are really bad on the high/low sides\n",
    "# creates poly1d object to calculate stdev, skew, and pctzero as a function of ppg\n",
    "# upper_extr prevents the function from sloping back down (or up) after hitting an extremum\n",
    "ff=pd.read_csv('params.csv')\n",
    "funcs={}\n",
    "def upper_extr(poly,mn,mx):\n",
    "    c=poly.c\n",
    "    if len(c) != 3 or c[0]==0:\n",
    "        return poly\n",
    "    x_extr=-0.5*c[1]/c[0]\n",
    "    val_extr=poly(x_extr)\n",
    "    if x_extr<mn or x_extr>mx:\n",
    "        return poly\n",
    "    return lambda lis: map(lambda x: val_extr if x > x_extr else poly(x), lis)\n",
    "    \n",
    "for p in pos:\n",
    "    funcs[p]={}\n",
    "    thispos=pf[pf['Pos']==p]\n",
    "    mn=thispos['MEAN'].min()\n",
    "    mx=thispos['MEAN'].max()\n",
    "    for q in quants:\n",
    "        funcs[p][q]=upper_extr(np.poly1d(ff[ff['Pos']==p][ff['Quantity']==q][['2','1','0']].values[0]),mn,mx)\n",
    "        \"\"\"print p, q\n",
    "        x = np.linspace(mn, mx, 200)\n",
    "        y = funcs[p][q](x)\n",
    "        plt.scatter(thispos['MEAN'], thispos[q])\n",
    "        plt.plot(x, y)\n",
    "        plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this loads player point projections and raw correlations from file, and creates a big correl matrix\n",
    "# players who appear later in the list get their skew adjusted downwards by the cholesky correl operation\n",
    "projs=pd.read_csv(os.path.expanduser('~/Dropbox/DFS/data/contests/Week{}/playervals.csv'.format(CUR_WEEK)))\n",
    "corrf=pd.read_csv(os.path.expanduser('~/Dropbox/DFS/data/players/pos_correls.csv'))\n",
    "projs.columns=['PID','points']\n",
    "hf1=hf[hf['Week']==CUR_WEEK][hf['Year']==CUR_YEAR].merge(projs, on=['PID'])[['PID','Pos','Team','Opp','points']]\n",
    "# adds each player's projected (from the function) stdev, skew and pz to the dataframe hf1\n",
    "for i, r in hf1.iterrows():\n",
    "    for q in quants:\n",
    "        hf1.set_value(i, q, funcs[r['Pos']][q]([r['points']])[0])\n",
    "hf1=hf1.merge(sals[['PID', 'Salary']], on=['PID'])\n",
    "hf1['PPD'] = hf1.apply(lambda r: r['points'] / r['Salary'], axis=1)\n",
    "nplyrs = hf1.shape[0]\n",
    "# creates big correlation matrix\n",
    "correls=np.zeros((nplyrs, nplyrs))\n",
    "for i in xrange(nplyrs):\n",
    "    correls[i,i]=1\n",
    "    for j in xrange(i+1,nplyrs):\n",
    "        p1,p2=hf1.loc[i], hf1.loc[j]\n",
    "        # if they're same team and they're not the same, and neither is DST, OR\n",
    "        # if opponents and one is DST but not both DST\n",
    "        if (p1['Team']==p2['Team'] and p1['Pos'] != p2['Pos'] and p1['Pos'] != 'DST' and p2['Pos'] != 'DST') \\\n",
    "            or (p1['Team']==p2['Opp'] and (p1['Pos']=='DST' or p2['Pos']=='DST') and not ((p1['Pos']=='DST' and p2['Pos']=='DST'))):\n",
    "            correls[i,j]=corrf[corrf['POS_PR']==p1['Pos'] + '_' + p2['Pos']]['CORR'].values[0]\n",
    "            correls[j,i]=correls[i,j]\n",
    "#np.savetxt(os.path.expanduser('~/Dropbox/DFS/data/players/correls.csv'), correls, delimiter=',', fmt='%.4f')\n",
    "# does monte carlo sample from skewed normal, and induces correlation using cholesky decomposition\n",
    "import skew_normal as sn\n",
    "mc_num=100000\n",
    "samples=[]\n",
    "player_idx = {}\n",
    "for i, row in hf1.iterrows():\n",
    "    sample = sn.random_skewnormal(mean=0., stdev=1., \n",
    "                                  skew=max(-0.98,min(0.98,row['SKEW'])), size=(mc_num))\n",
    "    bern = np.random.binomial(1,1-max(row['PZ'],0.),size=(mc_num))\n",
    "    samples.append(np.multiply(sample, bern).reshape(-1,1))\n",
    "    player_idx[row['PID']] = i\n",
    "indep = np.hstack(samples)\n",
    "import scipy.linalg as linalg\n",
    "cholesky = linalg.cholesky(correls)\n",
    "induc = np.dot(indep, cholesky)\n",
    "for c in xrange(induc.shape[1]):\n",
    "    plyr=hf1.loc[c]\n",
    "    induc[:,c] = induc[:,c] * plyr['STD'] + plyr['points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49200 124.306329718\n",
      "hi\n",
      "50000 120.844825432\n",
      "hi\n",
      "49600 113.210709806\n",
      "hi\n",
      "49700 110.514394889\n"
     ]
    }
   ],
   "source": [
    "# this segment randomly samples rosters. it's a terrible idea, the space is just too big\n",
    "\"\"\"\n",
    "import random\n",
    "cutoff = 1.\n",
    "num_lineups = 100000\n",
    "pool={}\n",
    "ranges={}\n",
    "for p in pos:\n",
    "    tmp = hf1[hf1['Pos']==p].sort_values('PPD', ascending=False)\n",
    "    pool[p] = tmp.sort_values('PPD', ascending=False).iloc[0:int(tmp.shape[0]*cutoff)]['PID']\n",
    "    ranges[p] = xrange(pool[p].shape[0])\n",
    "pos_lims = map(lambda l: dict(pr for pr in l),\n",
    "               [POSITION_LIMITS_RB_MAX, POSITION_LIMITS_TE_MAX, POSITION_LIMITS_WR_MAX])\n",
    "lineups = []\n",
    "for i in xrange(num_lineups):\n",
    "    salary = 100000\n",
    "    while (salary > 50000):\n",
    "        lineup = [0] * nplyrs\n",
    "        lim = pos_lims[np.random.randint(3)]\n",
    "        for p in lim:\n",
    "            for idx in map(lambda n: player_idx[n], list(pool[p].iloc[random.sample(ranges[p], lim[p])])):\n",
    "                lineup[idx] = 1\n",
    "        salary = sum(map(lambda i: lineup[i] * hf1.loc[i]['Salary'], range(nplyrs)))\n",
    "        ev = sum(map(lambda i: lineup[i] * hf1.loc[i]['points'], range(nplyrs)))\n",
    "    lineups.append(lineup)\n",
    "lineups = np.vstack(lineups)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outcomes = np.dot(lineups, induc.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131.25904533155193, 129.84304894927484, 128.2948112877877, 128.14444350966178, 127.81010943631179, 127.1237145064332, 127.05536856933766, 127.03348967086018, 126.81678828813347, 126.69021712293443, 126.4523754574931, 125.9534443427156, 125.90015564169273, 125.71736533015903, 125.65965381138446, 125.65910972226222, 125.63316350962459, 125.60375200015619, 125.58713757858214, 125.30557455828162, 125.26374888113764, 125.20804108620825, 124.92273701800482, 124.91482139373976, 124.82361966400205, 124.81779312378522, 124.64972557280463, 124.58954624110416, 124.52386250853645, 124.46145818806338, 124.32541509876179, 124.16078894935451, 124.15007696889795, 124.01862441970108, 123.98344819786072, 123.71716914665603, 123.65688697385363, 123.62101973426125, 123.60734086824642, 123.58846281100398, 123.46304028715657, 123.45867181243442, 123.27161047369682, 123.20639614129783, 123.12405293753544, 123.10385775107343, 123.05766249180431, 123.02486599333281, 122.92947672656419, 122.91921576080387, 122.8631215714863, 122.83957050852703, 122.82665585827505, 122.81292148753118, 122.75629559834432, 122.72893065839557, 122.66134730242467, 122.63726658940733, 122.62345124645339, 122.60816624107028, 122.60179521347982, 122.59595926637992, 122.58988330736241, 122.56561021402582, 122.53444165296798, 122.46779059673131, 122.36247245702668, 122.33540888842037, 122.30395939304481, 122.28670421438019, 122.24607536568573, 122.22576439807062, 122.2049896690032, 122.18256808704824, 122.06947042919607, 122.06704501907031, 122.06026390416955, 122.03927750425315, 121.91846636537704, 121.88075717267003, 121.865370886319, 121.84347007090919, 121.83707115594748, 121.8097882478547, 121.79114324518983, 121.74278404066189, 121.71143142658732, 121.68558877018654, 121.68337499870186, 121.58540891231227, 121.56700397617433, 121.56481118253227, 121.54400406420339, 121.50608702207163, 121.45885047285294, 121.44177288255047, 121.43047069465752, 121.3577682557156, 121.31290403633324, 121.1857251679284]\n"
     ]
    }
   ],
   "source": [
    "evs = []\n",
    "for i in xrange(lineups.shape[0]):\n",
    "    ev = 0\n",
    "    for j, l in enumerate(lineups[i]):\n",
    "        if l == 0:\n",
    "            continue\n",
    "        row = hf1.loc[j]\n",
    "        ev += row['points']\n",
    "    evs.append(ev)\n",
    "print sorted(evs, reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'PID', u'Pos', u'Team', u'Opp', u'points', u'PZ', u'STD', u'SKEW',\n",
       "       u'Salary', u'PPD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
